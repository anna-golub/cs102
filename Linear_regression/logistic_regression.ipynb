{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "from math import e, sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   class  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "data['class'] = iris.target\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия для двух классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, alpha=0.01, n_iter=1000, threshold=0.5, l2=0.01, intercept=False):\n",
    "        self.alpha = alpha\n",
    "        self.l2 = l2\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.n_iter = n_iter\n",
    "        self.intercept = intercept\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        precision = 0.001\n",
    "\n",
    "        if len(X.shape) == 1:\n",
    "            m, n = X.shape[0], 1\n",
    "        else:\n",
    "            m, n = X.shape\n",
    "\n",
    "        self.theta = np.full((n,), 0.33)\n",
    "        for j in range(self.n_iter):\n",
    "            theta_old = tuple(self.theta)\n",
    "\n",
    "            y_hypoth = X.dot(self.theta)\n",
    "            p = e ** y_hypoth / (e ** y_hypoth + 1)\n",
    "\n",
    "            self.grad = X.T.dot(p - y) / m\n",
    "            penalty = 2 * self.l2 * self.theta\n",
    "            if self.intercept:\n",
    "                penalty[0] = 0\n",
    "            self.grad += penalty\n",
    "\n",
    "#             check, J_plus, J_minus, diff = self.gradient_check(X, y)\n",
    "#             if not check:\n",
    "#                 print('gradient is incorrect!')\n",
    "#                 print(J_plus, J_minus, diff)\n",
    "#                 return\n",
    "\n",
    "            self.theta -= self.alpha * self.grad\n",
    "\n",
    "            precise = True\n",
    "            for i in range(n):\n",
    "                if abs(theta_old[i] - self.theta[i]) > precision:\n",
    "                    precise = False\n",
    "                    break\n",
    "            if precise:\n",
    "                print('iteration', str(j) + ': precise enough')\n",
    "                break\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_hypoth = X_test.dot(self.theta)\n",
    "        p = e ** y_hypoth / (e ** y_hypoth + 1)\n",
    "\n",
    "        get_predictions = lambda x: 1 if x > self.threshold else 0\n",
    "        return pd.Series(np.vectorize(get_predictions)(p)), p\n",
    "\n",
    "    def gradient_check(self, X, y):\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        if len(X.shape) == 1:\n",
    "            m, n = X.shape[0], 1\n",
    "        else:\n",
    "            m, n = X.shape[0], X.shape[1]\n",
    "\n",
    "        epsilon = 10e-7\n",
    "\n",
    "        for j in range(len(self.grad)):\n",
    "            vector = np.full((n,), 0)\n",
    "            vector[j] = 1\n",
    "\n",
    "            theta_plus = self.theta + vector * epsilon\n",
    "            y_hypoth_plus = X.dot(theta_plus)\n",
    "            p_plus = e ** y_hypoth_plus / (e ** y_hypoth_plus + 1)\n",
    "            J_plus = - sum(y * np.log(p_plus) + (1 - y) * np.log(1 - p_plus)) / m + self.l2 * sum(theta_plus ** 2)\n",
    "\n",
    "            theta_minus = self.theta - vector * epsilon\n",
    "            y_hypoth_minus = X.dot(theta_minus)\n",
    "            p_minus = e ** y_hypoth_minus / (e ** y_hypoth_minus + 1)\n",
    "            J_minus = - sum(y * np.log(p_minus) + (1 - y) * np.log(1 - p_minus)) / m + self.l2 * sum(theta_minus ** 2)\n",
    "\n",
    "            diff = abs((J_plus - J_minus) / (2 * epsilon) - self.grad[j])\n",
    "            if diff > epsilon:\n",
    "                return False, J_plus, J_minus, diff\n",
    "\n",
    "        return True, J_plus, J_minus, diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия для двух классов с использованием Mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBatchLR:\n",
    "    def __init__(self, alpha=0.01, epochs=100, batch_size=10, threshold=0.5, l2=0.01, intercept=False):\n",
    "        self.alpha = alpha\n",
    "        self.l2 = l2\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.intercept = intercept\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        precision = 0.001\n",
    "\n",
    "        if len(X.shape) == 1:\n",
    "            m, n = X.shape[0], 1\n",
    "        else:\n",
    "            m, n = X.shape\n",
    "\n",
    "        self.theta = np.full((n,), 0.33)\n",
    "        for j in range(self.epochs):\n",
    "            theta_old = tuple(self.theta)\n",
    "\n",
    "            for k in range(0, m, self.batch_size):\n",
    "                start = k\n",
    "                size = min(self.batch_size, m - k)\n",
    "                stop = k + size\n",
    "#                 print('start =', start, ' stop =', stop)\n",
    "\n",
    "                X_batch = X[start:stop]\n",
    "                y_batch = y[start:stop]\n",
    "\n",
    "                y_hypoth = X_batch.dot(self.theta)\n",
    "                p = e ** y_hypoth / (e ** y_hypoth + 1)\n",
    "\n",
    "                self.grad = X_batch.T.dot(p - y_batch) / size\n",
    "                penalty = 2 * self.l2 * self.theta\n",
    "\n",
    "                if self.intercept:\n",
    "                    penalty[0] = 0\n",
    "                self.grad += penalty\n",
    "                self.theta -= self.alpha * self.grad\n",
    "\n",
    "            precise = True\n",
    "            for i in range(n):\n",
    "                if abs(theta_old[i] - self.theta[i]) > precision:\n",
    "                    precise = False\n",
    "                    break\n",
    "            if precise:\n",
    "                print('epoch', str(j) + ': precise enough')\n",
    "                break\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_hypoth = X_test.dot(self.theta)\n",
    "        p = e ** y_hypoth / (e ** y_hypoth + 1)\n",
    "\n",
    "        get_predictions = lambda x: 1 if x > self.threshold else 0\n",
    "        return pd.Series(np.vectorize(get_predictions)(p)), p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики качества модели для двух классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_hypoth, y):\n",
    "    y_hypoth, y = np.array(y_hypoth), np.array(y)\n",
    "    tp = ((y_hypoth == y) & (y == 1)).sum()\n",
    "    fp = ((y == 0) & (y_hypoth == 1)).sum()\n",
    "    return tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_hypoth, y):\n",
    "    y_hypoth, y = np.array(y_hypoth), np.array(y)\n",
    "    tp = ((y_hypoth == y) & (y == 1)).sum()\n",
    "    fn = ((y_hypoth == 0) & (y == 1)).sum()\n",
    "    return tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_measure(y_hypoth, y):\n",
    "    pr, rec = precision(y_hypoth, y), recall(y_hypoth, y)\n",
    "    return 2 * pr * rec / (pr + rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(X):\n",
    "    if len(X.shape) == 1:\n",
    "        X = [(x - min(X)) / (max(X) - min(X)) for x in X]\n",
    "        return\n",
    "    \n",
    "    for col in X.columns:\n",
    "        if max(X[col]) == min(X[col]):\n",
    "            X[col] = 1\n",
    "        else:\n",
    "            X[col] = [(x - min(X[col])) / (max(X[col]) - min(X[col])) for x in X[col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение на данных про ирисы (классы 0 и 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.drop('class', axis=1), data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_two_class, y_two_class = data[data['class'] <= 1].drop('class', axis=1), data[data['class'] <= 1]['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>sepal length (cm)^2</th>\n",
       "      <th>sepal length (cm) sepal width (cm)</th>\n",
       "      <th>sepal length (cm) petal length (cm)</th>\n",
       "      <th>sepal length (cm) petal width (cm)</th>\n",
       "      <th>sepal width (cm)^2</th>\n",
       "      <th>sepal width (cm) petal length (cm)</th>\n",
       "      <th>sepal width (cm) petal width (cm)</th>\n",
       "      <th>petal length (cm)^2</th>\n",
       "      <th>petal length (cm) petal width (cm)</th>\n",
       "      <th>petal width (cm)^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>26.01</td>\n",
       "      <td>17.85</td>\n",
       "      <td>7.14</td>\n",
       "      <td>1.02</td>\n",
       "      <td>12.25</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>24.01</td>\n",
       "      <td>14.70</td>\n",
       "      <td>6.86</td>\n",
       "      <td>0.98</td>\n",
       "      <td>9.00</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>22.09</td>\n",
       "      <td>15.04</td>\n",
       "      <td>6.11</td>\n",
       "      <td>0.94</td>\n",
       "      <td>10.24</td>\n",
       "      <td>4.16</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>21.16</td>\n",
       "      <td>14.26</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.92</td>\n",
       "      <td>9.61</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.62</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12.96</td>\n",
       "      <td>5.04</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "0  1.0                5.1               3.5                1.4   \n",
       "1  1.0                4.9               3.0                1.4   \n",
       "2  1.0                4.7               3.2                1.3   \n",
       "3  1.0                4.6               3.1                1.5   \n",
       "4  1.0                5.0               3.6                1.4   \n",
       "\n",
       "   petal width (cm)  sepal length (cm)^2  sepal length (cm) sepal width (cm)  \\\n",
       "0               0.2                26.01                               17.85   \n",
       "1               0.2                24.01                               14.70   \n",
       "2               0.2                22.09                               15.04   \n",
       "3               0.2                21.16                               14.26   \n",
       "4               0.2                25.00                               18.00   \n",
       "\n",
       "   sepal length (cm) petal length (cm)  sepal length (cm) petal width (cm)  \\\n",
       "0                                 7.14                                1.02   \n",
       "1                                 6.86                                0.98   \n",
       "2                                 6.11                                0.94   \n",
       "3                                 6.90                                0.92   \n",
       "4                                 7.00                                1.00   \n",
       "\n",
       "   sepal width (cm)^2  sepal width (cm) petal length (cm)  \\\n",
       "0               12.25                                4.90   \n",
       "1                9.00                                4.20   \n",
       "2               10.24                                4.16   \n",
       "3                9.61                                4.65   \n",
       "4               12.96                                5.04   \n",
       "\n",
       "   sepal width (cm) petal width (cm)  petal length (cm)^2  \\\n",
       "0                               0.70                 1.96   \n",
       "1                               0.60                 1.96   \n",
       "2                               0.64                 1.69   \n",
       "3                               0.62                 2.25   \n",
       "4                               0.72                 1.96   \n",
       "\n",
       "   petal length (cm) petal width (cm)  petal width (cm)^2  \n",
       "0                                0.28                0.04  \n",
       "1                                0.28                0.04  \n",
       "2                                0.26                0.04  \n",
       "3                                0.30                0.04  \n",
       "4                                0.28                0.04  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(2, include_bias=True)\n",
    "X_two_class_poly = pd.DataFrame(data = poly.fit_transform(X_two_class), columns=poly.get_feature_names(X_two_class.columns))\n",
    "X_two_class_poly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max(X_two_class_poly)\n",
    "min_max(y_two_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 507: precise enough\n",
      "Wall time: 360 ms\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_two_class_poly, y_two_class, test_size=0.33, random_state=18)\n",
    "# model = LogisticRegression(alpha=0.01, threshold=0.5, l2=0.01, intercept=True)\n",
    "\n",
    "model = MiniBatchLR(alpha=0.01, epochs=10000, batch_size=10, threshold=0.5, l2=0.01, intercept=True)\n",
    "%time model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hypoth, pred_proba = model.predict(X_test)\n",
    "precision(Y_hypoth, Y_test), recall(Y_hypoth, Y_test), f_measure(Y_hypoth, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.52611646,  0.20739539, -0.8846714 ,  0.84175319,  0.84246498,\n",
       "        0.23901378, -0.51966476,  0.75169732,  0.78547712, -0.77729013,\n",
       "        0.58341294,  0.66333183,  0.83816077,  0.84164902,  0.75135035])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x4a4edb0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_proba.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия для K классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegression:\n",
    "    def __init__(self, alpha=0.01, epochs=100, batch_size=10, threshold=0.5, l2=0.01, intercept=False):\n",
    "        self.alpha = alpha\n",
    "        self.l2 = l2\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.intercept = intercept\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        precision = 0.001\n",
    "\n",
    "        if len(X.shape) == 1:\n",
    "            M, N = X.shape[0], 1\n",
    "        else:\n",
    "            M, N = X.shape\n",
    "        K = pd.Series(y).nunique()\n",
    "\n",
    "        self.theta = np.array([[0.33] * N for _ in range(K)])\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            if epoch % 10 == 0:\n",
    "                print('epoch', epoch)\n",
    "            \n",
    "            theta_old = [tuple(self.theta[j]) for j in range(K)]\n",
    "\n",
    "            for b in range(0, M, self.batch_size):\n",
    "                start = b\n",
    "                size = min(self.batch_size, M - b)\n",
    "                stop = b + size\n",
    "\n",
    "                X_batch = X[start:stop]\n",
    "                y_batch = y[start:stop]\n",
    "\n",
    "                y_hypoth = X_batch.dot(self.theta.T)\n",
    "                p = e ** y_hypoth\n",
    "                for i in range(size):\n",
    "                    p[i] /= sum(e ** y_hypoth[i])\n",
    "\n",
    "                self.grad = np.array([[0.0] * N for j in range(K)])\n",
    "                for j in range(K):\n",
    "                    for n in range(N):\n",
    "                        for i in range(size):\n",
    "                            if j == y_batch[i]:\n",
    "                                self.grad[j][n] += (p[i][j] - 1.0) * X_batch[i][n]\n",
    "                            else:\n",
    "                                self.grad[j][n] += p[i][j] * X_batch[i][n]\n",
    "                \n",
    "                penalty = 2 * self.l2 * self.theta\n",
    "                if self.intercept:\n",
    "                    penalty[:, 0] = 0.0\n",
    "                self.grad += penalty\n",
    "                \n",
    "                self.theta -= self.alpha * self.grad\n",
    "\n",
    "            precise = True\n",
    "            for j in range(K):\n",
    "                for n in range(N):\n",
    "                    if abs(theta_old[j][n] - self.theta[j][n]) > precision:\n",
    "                        precise = False\n",
    "                        break\n",
    "            if precise:\n",
    "                print('epoch', str(epoch) + ': precise enough')\n",
    "                break\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_test = np.array(X_test)\n",
    "        \n",
    "        y_hypoth = X_test.dot(self.theta.T)        \n",
    "        p = e ** y_hypoth\n",
    "        for i in range(len(X_test)):\n",
    "            p[i] /= sum(e ** y_hypoth[i])\n",
    "        \n",
    "        predictions = [p[i].argmax() for i in range(len(X_test))]\n",
    "        pred_proba = [max(p[i]) for i in range(len(X_test))]\n",
    "        return pd.Series(predictions), pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики качества модели для К классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_hypoth, y_test):\n",
    "    y_hypoth, y_test = np.array(y_hypoth), np.array(y_test)\n",
    "    classes = pd.Series(y_test).unique()\n",
    "    K = len(classes)\n",
    "    \n",
    "    confusion_matrix = [[0] * K for _ in range(K)]\n",
    "    for i in range(K):\n",
    "        for j in range(K):\n",
    "            confusion_matrix[i][j] = ((y_test == i) & (y_hypoth == j)).sum()\n",
    "    \n",
    "    tp, fp, fn = np.full((K,), 0), np.full((K,), 0), np.full((K,), 0)\n",
    "    for j in range(K):\n",
    "        tp[j] = confusion_matrix[j][j]\n",
    "        fp[j] = sum([confusion_matrix[i][j] for i in range(K)]) - tp[j]\n",
    "        fn[j] = sum(confusion_matrix[j]) - tp[j]\n",
    "    \n",
    "    pr_micro = sum(tp) / sum(tp + fp)\n",
    "    r_micro = sum(tp) / sum(tp + fn)\n",
    "    f_micro = 2 * pr_micro * r_micro / (pr_micro + r_micro)\n",
    "    \n",
    "    pr_macro = sum(tp / (tp + fp)) / K\n",
    "    r_macro = sum(tp / (tp + fn)) / K\n",
    "    f_macro = 2 * pr_macro * r_macro / (pr_macro + r_macro)\n",
    "    \n",
    "    return f_micro, f_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение на данных про ирисы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly = pd.DataFrame(data = poly.fit_transform(X), columns=poly.get_feature_names(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max(X_poly)\n",
    "min_max(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 397: precise enough\n",
      "Wall time: 6.12 s\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=18)\n",
    "model = SoftmaxRegression(alpha=0.01, epochs=1000, batch_size=10, threshold=0.5, l2=0.01, intercept=True)\n",
    "%time model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15970bd0>"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_hypoth, pred_proba = model.predict(X_test)\n",
    "pd.Series(pred_proba).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.98, 0.98080864542575)"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(Y_hypoth, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение на данных mnist/digits (распознавание рукописных цифр)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2     3     4     5    6    7    8    9   ...   54   55   56  \\\n",
       "0  0.0  0.0  5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  5.0  0.0  0.0   \n",
       "3  0.0  0.0  7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  9.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "    57   58    59    60    61   62   63  \n",
       "0  0.0  6.0  13.0  10.0   0.0  0.0  0.0  \n",
       "1  0.0  0.0  11.0  16.0  10.0  0.0  0.0  \n",
       "2  0.0  0.0   3.0  11.0  16.0  9.0  0.0  \n",
       "3  0.0  7.0  13.0  13.0   9.0  0.0  0.0  \n",
       "4  0.0  0.0   2.0  16.0   4.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "mnist = load_digits()\n",
    "data = pd.DataFrame(data=mnist.data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data, pd.Series(mnist.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "epoch 10\n",
      "epoch 20\n",
      "epoch 30\n",
      "epoch 40\n",
      "epoch 50\n",
      "epoch 60\n",
      "epoch 70\n",
      "epoch 80\n",
      "epoch 90\n",
      "Wall time: 10min 29s\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=18)\n",
    "model = SoftmaxRegression(alpha=0.01, epochs=100, batch_size=25, threshold=0.5, l2=0.1, intercept=True)\n",
    "%time model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15e9aa90>"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_hypoth, pred_proba = model.predict(X_test)\n",
    "pd.Series(pred_proba).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9191919191919192, 0.927033927599065)"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(Y_hypoth, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
